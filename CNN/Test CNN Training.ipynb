{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates training and testing a Convolutional Neural Network using the Keras Xception API to classify crop images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Arther-X/FarmBot-Crop-Image-Classifier\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image dataset I'm using is [Plant Seedlings Classification](https://www.kaggle.com/c/plant-seedlings-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Install dependency python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install opencv-python\n",
    "pip install keras\n",
    "pip install google\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- import -------\n",
    "\n",
    "## ------- Traing -------\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.applications.xception import *\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout, Dense, Input, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import imageio\n",
    "import PIL\n",
    "\n",
    "## ------- Testing -------\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "# ------- import end -------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Black-grass',\n",
    "          'Charlock',\n",
    "          'Cleavers',\n",
    "          'Common Chickweed',\n",
    "          'Common wheat',\n",
    "          'Fat Hen',\n",
    "          'Loose Silky-bent',\n",
    "          'Maize',\n",
    "          'Scentless Mayweed',\n",
    "          'Shepherds Purse',\n",
    "          'Small-flowered Cranesbill',\n",
    "          'Sugar beet']\n",
    "img_size = 299\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_img = np.zeros([4750, img_size, img_size, 3])\n",
    "train_label = np.zeros([4750, 1])\n",
    "\n",
    "i = 0\n",
    "for index, label in tqdm(enumerate(labels), total=len(labels)):\n",
    "    for file in os.listdir('data/plant-seedlings-classification/train/' + label):\n",
    "        im = imread('data/plant-seedlings-classification/train/{}/{}'.format(label, file), pilmode='RGB')\n",
    "        np_im = PIL.Image.fromarray(im)\n",
    "        train_img[i,:,:,:] = np.array(np_im.resize((img_size, img_size), PIL.Image.LANCZOS))\n",
    "        train_label[i] = index\n",
    "        i += 1\n",
    "\n",
    "train_label = np_utils.to_categorical(train_label, 12)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                             rotation_range=180,\n",
    "                             width_shift_range=0.3,\n",
    "                             height_shift_range=0.3,\n",
    "                             zoom_range=0.3,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "\n",
    "datagen.fit(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "296/296 [==============================] - 2953s 10s/step - loss: 0.8916 - accuracy: 0.7203\n",
      "Epoch 2/100\n",
      "296/296 [==============================] - 2875s 10s/step - loss: 0.3944 - accuracy: 0.8758\n",
      "Epoch 3/100\n",
      "296/296 [==============================] - 2815s 10s/step - loss: 0.3116 - accuracy: 0.9014\n",
      "Epoch 4/100\n",
      "296/296 [==============================] - 2803s 9s/step - loss: 0.2724 - accuracy: 0.9098\n",
      "Epoch 5/100\n",
      "296/296 [==============================] - 2801s 9s/step - loss: 0.2236 - accuracy: 0.9254\n",
      "Epoch 6/100\n",
      "296/296 [==============================] - 2774s 9s/step - loss: 0.2133 - accuracy: 0.9299\n",
      "Epoch 7/100\n",
      "296/296 [==============================] - 2753s 9s/step - loss: 0.2002 - accuracy: 0.9390\n",
      "Epoch 8/100\n",
      "296/296 [==============================] - 2760s 9s/step - loss: 0.1774 - accuracy: 0.9440\n",
      "Epoch 9/100\n",
      "296/296 [==============================] - 2795s 9s/step - loss: 0.1678 - accuracy: 0.9474\n",
      "Epoch 10/100\n",
      "296/296 [==============================] - 2796s 9s/step - loss: 0.1453 - accuracy: 0.9537\n",
      "Epoch 11/100\n",
      "209/296 [====================>.........] - ETA: 13:43 - loss: 0.1549 - accuracy: 0.9554"
     ]
    }
   ],
   "source": [
    "base_model = Xception(weights='imagenet', input_shape=(img_size, img_size, 3), include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='Adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(datagen.flow(train_img, train_label, batch_size=batch_size), steps_per_epoch=len(train_img)//batch_size, epochs=10, verbose=1)\n",
    "model.save_weights('Xception.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                             rotation_range=180,\n",
    "                             width_shift_range=0.3,\n",
    "                             height_shift_range=0.3,\n",
    "                             zoom_range=0.3,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True)\n",
    "\n",
    "\n",
    "base_model = Xception(weights=None, include_top=False, input_shape=(img_size, img_size, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.load_weights('Xception.h5')\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('file,species\\n')\n",
    "    for file in tqdm(os.listdir('seg_test/')):\n",
    "        img = image.load_img(os.path.join('seg_test', file), target_size=(img_size, img_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        pred = np.zeros([12,])\n",
    "        for i, im in enumerate(datagen.flow(x)):\n",
    "            pred += model.predict(im)[0]\n",
    "            if i > 100:\n",
    "                break\n",
    "        f.write('{},{}\\n'.format(file, labels[np.where(pred==np.max(pred))[0][0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
